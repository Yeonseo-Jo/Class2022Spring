{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pipeline.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yeonseo-Jo/Class2022Spring/blob/main/(15)%20pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Huggingface pipelines](https://huggingface.co/docs/transformers/v4.19.2/en/main_classes/pipelines)\n",
        "\n",
        "* The pipelines are a great and easy way to use models for inference(=바로 사용할 수 있는 model). These pipelines are objects that abstract most of the complex code from the library, offering a simple API dedicated to several tasks, including Named Entity Recognition, Masked Language Modeling, Sentiment Analysis, Feature Extraction and Question Answerin\n",
        "\n",
        "* <b> pipeline = 아주 간단한 함수의 형태\n",
        "\n",
        " = 입력과 출력만 알면 됨 </b>\n",
        "\n",
        " * task별로 pipline을 만들어놨음 (task-specific pipeline)"
      ],
      "metadata": {
        "id": "Hsb22sODAkiu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igcmeYcHSWUs"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"audio-classification\")\n",
        "# pipeline은 task-specific하므로 task 파라미터로 어떤 task를 수행할 함수를 만들건지 지정 해야함\n",
        "# model 파라미터로 특정 model을 지정할 수 있음. / 지금의 코드처럼 model 파라미터를 쓰지 않을 경우 default로 적혀 있는 모델 하나를 가져옴\n",
        "# => No model was supplied, defaulted to superb/wav2vec2-base-superb-ks (https://huggingface.co/superb/wav2vec2-base-superb-ks) => keyword spotting model\n",
        " # = model 파라미터를 입력하지 않았으므로 defuault로 다음 url의 모델을 가져온다\n",
        "\n",
        "\n",
        "#참고) pipeline을 사용해서 gradio에 넣는 경우 pipeline이 이미 함수 (input, output만 정해주면 됨)이므로 바로 gradio에 넣을 수 있음. "
      ],
      "metadata": {
        "id": "AbTafwBzZm_v",
        "outputId": "8dbf1580-51d8-4391-e40d-8408aa625023",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to superb/wav2vec2-base-superb-ks (https://huggingface.co/superb/wav2vec2-base-superb-ks)\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py:364: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pipeline 함수를 사용하려면\n",
        "# pipe(\"...wav\") => input으로 넣을 wav 파일을 함수에 넣어줌\n",
        "\n",
        "#pipeline 함수의 장점: 복잡하게 함수를 만들 필요 없고 task와 model을 지정해주고 input을 넣어주면 사용가능하다."
      ],
      "metadata": {
        "id": "cKVTD8GljTQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> [emotional speech dataset for audio-classification\n",
        "](https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio?resource=download)\n",
        "\n",
        "    = emotinal speech에 대한 audio 파일이 있는 링크\n",
        "\n",
        "* kaggle: 데이터를 모아놓는 유용한 사이트\n"
      ],
      "metadata": {
        "id": "fcAxqFJW7cQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"automatic-speech-recognition\")\n",
        "\n",
        "#No model was supplied, defaulted to facebook/wav2vec2-base-960h (https://huggingface.co/facebook/wav2vec2-base-960h) => default 모델"
      ],
      "metadata": {
        "id": "Du0I-rPQZnLs",
        "outputId": "9a36e023-1260-45ca-a700-dba4695ef565",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/wav2vec2-base-960h (https://huggingface.co/facebook/wav2vec2-base-960h)\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"conversational\")\n",
        "\n",
        "#No model was supplied, defaulted to microsoft/DialoGPT-medium (https://huggingface.co/microsoft/DialoGPT-medium) => default model = 챗봇 모델!\n"
      ],
      "metadata": {
        "id": "9Ea2WaXWeYzO",
        "outputId": "76345195-ac4a-4d31-fa34-c657519eb165",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to microsoft/DialoGPT-medium (https://huggingface.co/microsoft/DialoGPT-medium)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Conversation\n",
        "\n",
        "conversation_1 = Conversation(\"Going to the movies tonight - any suggestions?\")\n",
        "conversation_2 = Conversation(\"What's the last book you have read?\")\n",
        "pipe([conversation_1, conversation_2])                                   # =>conversation 1,2를 리스트 형태로 해서 pipe 함수에 넣기"
      ],
      "metadata": {
        "id": "2aR1i5xPhBgK",
        "outputId": "cde64be7-3233-4618-da86-f674b924a7d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Conversation id: 58c1bdc7-32e1-4815-acaf-9276dad5adae \n",
              " user >> Going to the movies tonight - any suggestions? \n",
              " bot >> The Big Lebowski ,\n",
              " Conversation id: bf9c0f03-5709-4c96-a245-a9144385f1ca \n",
              " user >> What's the last book you have read? \n",
              " bot >> The Last Question ]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_1.add_user_input(\"Is it an action movie?\")                      #답변에 대해 추가 질문 넣기\n",
        "conversation_2.add_user_input(\"What is the genre of this book?\")\n",
        "pipe([conversation_1, conversation_2])"
      ],
      "metadata": {
        "id": "7mz4btXyD2ac",
        "outputId": "60301ec1-49b5-481a-d0f2-80a77f62fcf1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Conversation id: 58c1bdc7-32e1-4815-acaf-9276dad5adae \n",
              " user >> Going to the movies tonight - any suggestions? \n",
              " bot >> The Big Lebowski \n",
              " user >> Is it an action movie? \n",
              " bot >> It's a comedy. , Conversation id: bf9c0f03-5709-4c96-a245-a9144385f1ca \n",
              " user >> What's the last book you have read? \n",
              " bot >> The Last Question \n",
              " user >> What is the genre of this book? \n",
              " bot >> I'm not sure, but I think it's fantasy. ]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"feature-extraction\")\n",
        "\n",
        "#feature = vector 값"
      ],
      "metadata": {
        "id": "jKmV7A0peiOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"What's the last book you have read?\") #문장 비교"
      ],
      "metadata": {
        "id": "fOr2SXf-keIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"fill-mask\") #default model: distilroverta-base"
      ],
      "metadata": {
        "id": "tZzfAxb7Zm8r",
        "outputId": "8cadbe5b-e483-4d07-9f5b-6db377366272",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilroberta-base (https://huggingface.co/distilroberta-base)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"The goal of life is <mask>.\")"
      ],
      "metadata": {
        "id": "oPlKmG9LNaZ8",
        "outputId": "bd747512-cf57-4b74-ef1f-2bb8b5e76e76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.06897159665822983,\n",
              "  'sequence': 'The goal of life is happiness.',\n",
              "  'token': 11098,\n",
              "  'token_str': ' happiness'},\n",
              " {'score': 0.06554926186800003,\n",
              "  'sequence': 'The goal of life is immortality.',\n",
              "  'token': 45075,\n",
              "  'token_str': ' immortality'},\n",
              " {'score': 0.03235739469528198,\n",
              "  'sequence': 'The goal of life is yours.',\n",
              "  'token': 14314,\n",
              "  'token_str': ' yours'},\n",
              " {'score': 0.0243137888610363,\n",
              "  'sequence': 'The goal of life is liberation.',\n",
              "  'token': 22211,\n",
              "  'token_str': ' liberation'},\n",
              " {'score': 0.02376791648566723,\n",
              "  'sequence': 'The goal of life is simplicity.',\n",
              "  'token': 25342,\n",
              "  'token_str': ' simplicity'}]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"image-classification\")       #이미지 classify"
      ],
      "metadata": {
        "id": "HapJJtnzeiKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe  = pipeline(task=\"image-segmentation\")          #이미지 segment 분리"
      ],
      "metadata": {
        "id": "tf-V7IdlZm5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"ner\")                     #name-entity-recognition : 단어의 category 추출 (사람, 장소 ,,,)"
      ],
      "metadata": {
        "id": "mFB501JrZm28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"object-detection\")        #이미지, 영상에 어떤 object가 있는지 알려줌"
      ],
      "metadata": {
        "id": "yfYGY75aZmzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"question-answering\")      #paragraph에 대해 질문을 하면 대답 해줌"
      ],
      "metadata": {
        "id": "1AMf356WZnFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"sentiment-analysis\")        #posivie/negative 중 어디에 가까운지 알려줌"
      ],
      "metadata": {
        "id": "zKrTtHNZZnIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"I love movie a lot\")"
      ],
      "metadata": {
        "id": "JrKCgRdXtti0",
        "outputId": "bffda30a-ab3a-405e-ec93-ed1ec3599ad0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9997860789299011}]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"summarization\")       #요약"
      ],
      "metadata": {
        "id": "gEEd-jBMeiGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "!pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "# maybe need to restart runtime\n",
        "pipe = pipeline(task=\"table-question-answering\")\n",
        "#No model was supplied, defaulted to google/tapas-base-finetuned-wtq (https://huggingface.co/google/tapas-base-finetuned-wtq)\n",
        "\n",
        "#table-question-aswering이란 dataframe의 형태로 데이터가 주어졌을때, 질문을 하면 답을 맞춰줌"
      ],
      "metadata": {
        "id": "HsuJwwnde7eR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    \"actors\": [\"brad pitt\", \"leonardo di caprio\", \"george clooney\"],\n",
        "    \"age\": [\"56\", \"45\", \"59\"],\n",
        "    \"number of movies\": [\"87\", \"53\", \"69\"],\n",
        "    \"date of birth\": [\"7 february 1967\", \"10 june 1996\", \"28 november 1967\"],\n",
        "}\n",
        "pipe(data, 'how old is brad pitt?')"
      ],
      "metadata": {
        "id": "A0E0kRi6jukT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"text-classification\")      #위에서 했던 sentiment-analysis와 유사함 (포함관계)       ->negative/positive 중 어디에 가까웅ㄴ지"
      ],
      "metadata": {
        "id": "8VrTCfJOZnCm",
        "outputId": "874981e4-30e1-4682-fd48-43e8f1ccff77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"text-generation\")          #일부의 text를 주면 나머지 text를 generate 해줌"
      ],
      "metadata": {
        "id": "1qrC5pVvZcD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"My name is Hosung Nam. I work at Korea University\")"
      ],
      "metadata": {
        "id": "WIP8lo73uykz",
        "outputId": "f64dc2f7-c471-4240-ae04-28954a65c1d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \"My name is Hosung Nam. I work at Korea University in Seoul, Korea. My work has influenced so many so in particular so many kinds of work. So many of Korea University so many different sorts of works. So much work it's hard\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"text2text-generation\")    #text-generation과 유사"
      ],
      "metadata": {
        "id": "czfn1yYjfC2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"token-classification\")          #token = 하나하나의 단어가 무엇인지 맞춰줌"
      ],
      "metadata": {
        "id": "saYq0rnbZmxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"translation_en_to_de\")          #영어를 독일어로 번역해줌"
      ],
      "metadata": {
        "id": "jGdtdjn9fV4K",
        "outputId": "0669a8e9-e7dc-446a-938c-82146aef2973",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to t5-base (https://huggingface.co/t5-base)\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/t5/tokenization_t5_fast.py:161: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"I love you\")"
      ],
      "metadata": {
        "id": "f39fqbtuvIBj",
        "outputId": "2af632c3-4651-4dec-d525-cd932d49ece9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'translation_text': 'Ich liebe Sie'}]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"zero-shot-classification\")           #모델에게 label을 가르쳐주지 않고 모델에게 한번도 해보지 않은 질문을 함"
      ],
      "metadata": {
        "id": "54J0T-l6fVtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"one day I will see the world\", ['travel', 'cooking', 'dancing'])        #모델에게 이것이 어떤 유형의 text인지 맞추도록 함\n",
        "\n",
        "#-> 어떤 label인지 그 확률과 함께 보여줌"
      ],
      "metadata": {
        "id": "OZj3g-LgEftq",
        "outputId": "8526c4cc-c3ab-47e4-a8b6-e99171bbbf0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'labels': ['travel', 'dancing', 'cooking'],\n",
              " 'scores': [0.9938650727272034, 0.0032737888395786285, 0.0028610320296138525],\n",
              " 'sequence': 'one day I will see the world'}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"zero-shot-image-classification\")           #이미지 label을 맞추도록 훈련 (label을 사전에 줘서 훈련시키지 않은채로)"
      ],
      "metadata": {
        "id": "e8B335KufW17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
        "pipe(url, candidate_labels=[\"a photo of a cat\", \"a photo of a dog\"])"
      ],
      "metadata": {
        "id": "epMvhF4sE8pJ",
        "outputId": "78359464-f76c-44b4-d429-a47e38028bde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'a photo of a cat', 'score': 0.9974083304405212},\n",
              " {'label': 'a photo of a dog', 'score': 0.002591644646599889}]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}